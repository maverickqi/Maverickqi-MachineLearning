{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分类-参数\n",
    "AdaBoostClassifier(base_estimator=None, n_estimators=50, learning_rate=1.0, algorithm=’SAMME.R’, random_state=None) 这个函数，其中有几个比较主要的参数：\n",
    "\n",
    "base_estimator：代表的是弱分类器。在 AdaBoost 的分类器和回归器中都有这个参数，在 AdaBoost 中默认使用的是决策树，一般我们不需要修改这个参数，当然你也可以指定具体的分类器。\n",
    "\n",
    "n_estimators：算法的最大迭代次数，也是分类器的个数，每一次迭代都会引入一个新的弱分类器来增加原有的分类器的组合能力。默认是 50。\n",
    "\n",
    "learning_rate：代表学习率，取值在 0-1 之间，默认是 1.0。如果学习率较小，就需要比较多的迭代次数才能收敛，也就是说学习率和迭代次数是有相关性的。当你调整 learning_rate 的时候，往往也需要调整 n_estimators 这个参数。\n",
    "\n",
    "algorithm：代表我们要采用哪种 boosting 算法，一共有两种选择：SAMME 和 SAMME.R。默认是 SAMME.R。这两者之间的区别在于对弱分类权重的计算方式不同。\n",
    "\n",
    "random_state：代表随机数种子的设置，默认是 None。随机种子是用来控制随机模式的，当随机种子取了一个值，也就确定了一种随机规则，其他人取这个值可以得到同样的结果。如果不设置随机种子，每次得到的随机数也就不同。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 回归-参数\n",
    "AdaBoostRegressor(base_estimator=None, n_estimators=50, learning_rate=1.0, loss=‘linear’, random_state=None) \n",
    "\n",
    "回归和分类的参数基本是一致的，不同点在于回归算法里没有 algorithm 这个参数，但多了一个 loss 参数。\n",
    "\n",
    "loss 代表损失函数的设置，一共有 3 种选择，分别为 linear、square 和 exponential，它们的含义分别是线性、平方和指数。默认是线性。一般采用线性就可以得到不错的效果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1、获取/划分数据\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = load_boston()\n",
    "x_train, x_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "均方误差 =  16.38\n"
     ]
    }
   ],
   "source": [
    "# 2、AdaBoost预测\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "# 使用AdaBoost回归模型\n",
    "estimator = AdaBoostRegressor()\n",
    "estimator.fit(x_train,y_train)\n",
    "\n",
    "y_predict = estimator.predict(x_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_predict)\n",
    "# print(\"房价预测结果 \", y_predict)\n",
    "print(\"均方误差 = \",round(mse,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "决策树均方误差 =  16.7\n"
     ]
    }
   ],
   "source": [
    "# 3、使用决策树回归模型\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "estimator=DecisionTreeRegressor()\n",
    "estimator.fit(x_train,y_train)\n",
    "y_predict = estimator.predict(x_test)\n",
    "mse = mean_squared_error(y_test, y_predict)\n",
    "print(\"决策树均方误差 = \",round(mse,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN均方误差 =  43.2\n"
     ]
    }
   ],
   "source": [
    "# 4、使用KNN回归模型\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "estimator=KNeighborsRegressor()\n",
    "estimator.fit(x_train,y_train)\n",
    "y_predict = estimator.predict(x_test)\n",
    "mse = mean_squared_error(y_test, y_predict)\n",
    "print(\"KNN均方误差 = \",round(mse,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
